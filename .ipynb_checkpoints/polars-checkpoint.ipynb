{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dff9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aharte/virtual/lib/python3.10/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "%load_ext memory_profiler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87fdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  ds.dataset(\"~/internal/data/trade_taq2019.arrow\", format = \"arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7174a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data into scan...\n",
      "running window query...\n",
      "peak memory: 4668.07 MiB, increment: 0.00 MiB\n",
      "peak memory: 4633.32 MiB, increment: -26.45 MiB\n",
      "peak memory: 4047.43 MiB, increment: -347.94 MiB\n",
      "peak memory: 2127.42 MiB, increment: -728.03 MiB\n",
      "peak memory: 1202.44 MiB, increment: -92.51 MiB\n",
      "peak memory: 1186.02 MiB, increment: 0.00 MiB\n",
      "peak memory: 1186.06 MiB, increment: 0.00 MiB\n",
      "peak memory: 1186.06 MiB, increment: 0.00 MiB\n",
      "313 ms ± 64.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def window(data):\n",
    "    \n",
    "    # make the scanner\n",
    "    print(\"data into scan...\")\n",
    "    data = pl.scan_ds(data, allow_pyarrow_filter=True)\n",
    "    \n",
    "    # QUERY\n",
    "    print(\"running window query...\")\n",
    "    results = data.filter(\n",
    "        (pl.col(\"Symbol\") == \"AAPL\")&\n",
    "        (pl.col(\"Sale_Condition\").str.contains(\"O\"))&\n",
    "        (pl.col(\"Time\").is_between(datetime(2019,10,7,9,30), datetime(2019,10,7,16,0)))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n",
    "query = window(data)\n",
    "\n",
    "result=query.collect()\n",
    "result\n",
    "\n",
    "%timeit %memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d9ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting on time first...\n",
      "running query now\n",
      "peak memory: 1284.57 MiB, increment: -45.26 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "peak memory: 1284.58 MiB, increment: 0.00 MiB\n",
      "272 ms ± 4.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def agg(data):\n",
    "    \n",
    "    data = pl.scan_ds(data, allow_pyarrow_filter=True)\n",
    "    \n",
    "    #sort the data first\n",
    "    print(\"Sorting on time first...\")\n",
    "    data = data.sort(\"Time\")\n",
    "    \n",
    "    #run the agg query\n",
    "    print(\"running query now\")\n",
    "    \n",
    "    result = data.groupby_dynamic(index_column=\"Time\", every=\"1m\", period=\"1m\", by=\"Symbol\").agg(\n",
    "    [\n",
    "        pl.col(\"Trade_Volume\").sum().alias(\"Total_vol\")\n",
    "    ])\n",
    "    \n",
    "    return result\n",
    "\n",
    "query = agg(data)\n",
    "result = query.collect()\n",
    "result\n",
    "%timeit %memit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b11106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query...\n",
      "peak memory: 2062.24 MiB, increment: -122.69 MiB\n",
      "peak memory: 1720.03 MiB, increment: -157.34 MiB\n",
      "peak memory: 1581.11 MiB, increment: -58.12 MiB\n",
      "peak memory: 1466.73 MiB, increment: -11.58 MiB\n",
      "peak memory: 1462.02 MiB, increment: 0.00 MiB\n",
      "peak memory: 1462.02 MiB, increment: 0.00 MiB\n",
      "peak memory: 1460.13 MiB, increment: 0.00 MiB\n",
      "peak memory: 1455.33 MiB, increment: -4.80 MiB\n",
      "279 ms ± 13.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def newagg(data):\n",
    "    \n",
    "    data = pl.scan_ds(data, allow_pyarrow_filter=True)\n",
    "    print (\"running query...\")\n",
    "    result = data.groupby([\"Symbol\",\"Exchange\"]).agg(\n",
    "        [\n",
    "            pl.col(\"Trade_Price\").mean().alias(\"avg price\"),\n",
    "            pl.col(\"Trade_Volume\").mean().alias(\"avg volume\")\n",
    "        ]\n",
    "    ).sort(\"avg price\", reverse = True)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "query = newagg(data)\n",
    "result = query.collect()\n",
    "result\n",
    "%timeit %memit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103c3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data ingest of the bigger datset\n",
    "data = ds.dataset(\"~/internal/data/quote_taq2019.arrow\", format = \"arrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ff26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting on time\n",
      "running big query\n",
      "peak memory: 1475.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.68 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.68 MiB, increment: 0.00 MiB\n",
      "peak memory: 1475.68 MiB, increment: 0.00 MiB\n",
      "289 ms ± 7.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def bagg(data):\n",
    "\n",
    "    data = pl.scan_ds(data)\n",
    "    print(\"sorting on time\")\n",
    "    data = data.sort(\"Time\")\n",
    "\n",
    "    #QUERY\n",
    "    print(\"running big query\")\n",
    "    data = data.groupby_dynamic(index_column=\"Time\", every=\"1h\", period=\"1h\", by=\"Symbol\").agg(\n",
    "            [\n",
    "                (0.5*(pl.col(\"Bid_Price\")+pl.col(\"Offer_Price\")).mean()).alias(\"mid\"),\n",
    "                pl.col(\"Time\").min().alias(\"min_time\"),\n",
    "                pl.col(\"Time\").max().alias(\"max_time\")\n",
    "\n",
    "                ]\n",
    "            ).sort(\"Time\")\n",
    "    return data\n",
    "\n",
    "query = bagg(data)\n",
    "result = query.collect()\n",
    "result\n",
    "\n",
    "\n",
    "%timeit %memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1897e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
